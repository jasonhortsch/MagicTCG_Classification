{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split, KFold, cross_val_score\n",
    "import sklearn.metrics as sk\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({u'Black': 1576,\n",
       "         u'Blue': 1573,\n",
       "         u'Green': 1566,\n",
       "         u'Red': 1575,\n",
       "         u'White': 1584})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modern = pd.read_pickle('data/5color_modern_no_name_hardmode.pkl')\n",
    "Counter(modern.colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1,161 words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "y = pd.get_dummies(modern.colors)\n",
    "\n",
    "X = vectorizer.fit_transform(modern.text)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, y, random_state=42)\n",
    "\n",
    "xTrain = np.asarray(xTrain.todense())\n",
    "xTest  = np.asarray(xTest.todense())\n",
    "yTrain = np.asarray(yTrain)\n",
    "yTest  = np.asarray(yTest)\n",
    "\n",
    "def shuffle(x, y):\n",
    "    # helper function to shuffle indicies each loop \n",
    "    index = np.random.choice(len(x), len(x), replace=False)\n",
    "    return x[index], y[index]\n",
    "\n",
    "\n",
    "print \"There are {:,} words in the vocabulary.\".format(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 0     Test: 0.533333333333 Train: 0.575850340136\n",
      "Round: 1     Test: 0.572916666667 Train: 0.618537414966\n",
      "Round: 2     Test: 0.605208333333 Train: 0.661904761905\n",
      "Round: 3     Test: 0.638541666667 Train: 0.700170068027\n",
      "Round: 4     Test: 0.652083333333 Train: 0.72619047619\n",
      "Round: 5     Test: 0.685416666667 Train: 0.745408163265\n",
      "Round: 6     Test: 0.690625       Train: 0.763945578231\n",
      "Round: 7     Test: 0.692708333333 Train: 0.781292517007\n",
      "Round: 8     Test: 0.691666666667 Train: 0.793367346939\n",
      "Round: 9     Test: 0.7015625      Train: 0.800170068027\n",
      "Round: 10    Test: 0.713541666667 Train: 0.815136054422\n",
      "Round: 11    Test: 0.70625        Train: 0.822959183673\n",
      "Round: 12    Test: 0.713541666667 Train: 0.825   \n",
      "Round: 13    Test: 0.719791666667 Train: 0.839285714286\n",
      "Round: 14    Test: 0.721875       Train: 0.843027210884\n",
      "Round: 15    Test: 0.722395833333 Train: 0.840306122449\n",
      "Round: 16    Test: 0.730729166667 Train: 0.851530612245\n",
      "Round: 17    Test: 0.729166666667 Train: 0.859693877551\n",
      "Round: 18    Test: 0.721354166667 Train: 0.863605442177\n",
      "Round: 19    Test: 0.716666666667 Train: 0.867006802721\n",
      "Round: 20    Test: 0.730729166667 Train: 0.873129251701\n",
      "Round: 21    Test: 0.736458333333 Train: 0.880102040816\n",
      "Round: 22    Test: 0.721875       Train: 0.877380952381\n",
      "Round: 23    Test: 0.728125       Train: 0.884183673469\n",
      "Round: 24    Test: 0.7359375      Train: 0.88231292517\n",
      "Round: 25    Test: 0.731770833333 Train: 0.892006802721\n",
      "Round: 26    Test: 0.730208333333 Train: 0.89387755102\n",
      "Round: 27    Test: 0.725          Train: 0.899489795918\n",
      "Round: 28    Test: 0.724479166667 Train: 0.897108843537\n",
      "Round: 29    Test: 0.728125       Train: 0.905442176871\n",
      "Round: 30    Test: 0.7296875      Train: 0.905612244898\n",
      "Round: 31    Test: 0.733854166667 Train: 0.905442176871\n",
      "Round: 32    Test: 0.7328125      Train: 0.90731292517\n",
      "Round: 33    Test: 0.720833333333 Train: 0.908333333333\n",
      "Round: 34    Test: 0.7359375      Train: 0.910204081633\n",
      "Round: 35    Test: 0.727083333333 Train: 0.911394557823\n",
      "Round: 36    Test: 0.731770833333 Train: 0.917857142857\n",
      "Round: 37    Test: 0.736979166667 Train: 0.916836734694\n",
      "Round: 38    Test: 0.720833333333 Train: 0.918197278912\n",
      "Round: 39    Test: 0.723958333333 Train: 0.919557823129\n",
      "Round: 40    Test: 0.723958333333 Train: 0.924149659864\n",
      "Round: 41    Test: 0.728645833333 Train: 0.924149659864\n",
      "Round: 42    Test: 0.724479166667 Train: 0.923639455782\n",
      "Round: 43    Test: 0.7265625      Train: 0.928741496599\n",
      "Round: 44    Test: 0.727604166667 Train: 0.926020408163\n",
      "Round: 45    Test: 0.731770833333 Train: 0.929761904762\n",
      "Round: 46    Test: 0.726041666667 Train: 0.930102040816\n",
      "Round: 47    Test: 0.731770833333 Train: 0.929081632653\n",
      "Round: 48    Test: 0.734375       Train: 0.930782312925\n",
      "Round: 49    Test: 0.722395833333 Train: 0.933843537415\n",
      "Round: 50    Test: 0.730729166667 Train: 0.934693877551\n",
      "\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\" glorot 4-layer: batch, drop, batch, drop, batch drop \n",
    "    random indexing without replacement, ELU, epsilon=1e-9  \"\"\"\n",
    "\n",
    "# batch normalization code adapted from \n",
    "# https://groups.google.com/forum/#!topic/theano-users/dMV6aabL1Ds \n",
    "\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.nnet.bn import batch_normalization\n",
    "import numpy as np\n",
    "\n",
    "srng = RandomStreams()\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    (h, w) = shape\n",
    "    # Glorot normalization - last factor depends on non-linearity\n",
    "    # 0.25 for sigmoid and 0.1 for softmax, 1.0 for tanh or Relu\n",
    "    normalizer = 2.0 * np.sqrt(6) / np.sqrt(h + w) * 1.0\n",
    "    return theano.shared(floatX((np.random.random_sample(shape) - 0.5) * normalizer))\n",
    "\n",
    "def rectify(X, alpha=0.01):\n",
    "#     return T.maximum(X, 0.)\n",
    "#    return T.maximum(X, 0.1*X)  #leaky rectifier\n",
    "     return T.switch(X > 0, X, alpha * (T.exp(X) - 1)) # ELU\n",
    "\n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.99, epsilon=1e-9):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "\n",
    "\n",
    "def model(X, w_h, b_h, g_h, bb_h, w_h2, b_h2, g_h2, bb_h2, \n",
    "          w_o, b_ho, g_ho, bb_ho, p_drop_input, p_drop_hidden):\n",
    "    X = T.dot(X, w_h) + b_h\n",
    "    X = batch_normalization(X, gamma= g_h, beta= bb_h, \n",
    "                            mean= X.mean((0,), keepdims=True),\n",
    "                            std= T.ones_like(X.var((0,), keepdims = True)), \n",
    "                            mode='high_mem') \n",
    "    X = dropout(X, p_drop_hidden)\n",
    "    h = rectify(X)\n",
    "\n",
    "    h  = T.dot(h, w_h2) + b_h2\n",
    "    h = batch_normalization(h, gamma= g_h2, beta= bb_h2, \n",
    "                            mean= h.mean((0,), keepdims=True),\n",
    "                            std= T.ones_like(h.var((0,), keepdims = True)), \n",
    "                            mode='high_mem') \n",
    "    h = dropout(h, p_drop_hidden)\n",
    "    h2 = rectify(h)\n",
    "\n",
    "    h2 = T.dot(h2, w_o) + b_ho\n",
    "    h2 = batch_normalization(h2, gamma= g_ho, beta= bb_ho, \n",
    "                            mean= h2.mean((0,), keepdims=True),\n",
    "                            std= T.ones_like(h2.var((0,), keepdims = True)), \n",
    "                            mode='high_mem') \n",
    "    h2 = dropout(h2, p_drop_hidden)\n",
    "    py_x = softmax(h2)\n",
    "    return h, h2, py_x\n",
    "\n",
    "\n",
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "batch_size = 60\n",
    "\n",
    "h1_size = 600\n",
    "h2_size = 550\n",
    "\n",
    "w_h = init_weights((len(vectorizer.vocabulary_), h1_size))\n",
    "b_h = theano.shared(floatX(np.zeros(h1_size)))\n",
    "g_h = theano.shared(floatX(np.ones((h1_size))))\n",
    "bb_h = theano.shared(floatX(np.zeros((h1_size))))\n",
    "\n",
    "w_h2 = init_weights((h1_size, h2_size))\n",
    "b_h2 = theano.shared(floatX(np.zeros(h2_size)))\n",
    "g_h2 = theano.shared(floatX(np.ones((h2_size))))\n",
    "bb_h2 = theano.shared(floatX(np.zeros((h2_size))))\n",
    "\n",
    "w_o = init_weights((h2_size, yTest.shape[1]))\n",
    "b_ho = theano.shared(floatX(np.zeros(yTest.shape[1])))\n",
    "g_ho = theano.shared(floatX(np.ones((yTest.shape[1]))))\n",
    "bb_ho = theano.shared(floatX(np.zeros((yTest.shape[1]))))\n",
    "\n",
    "noise_h, noise_h2, noise_py_x = model(X, w_h, b_h, g_h, bb_h, \n",
    "                                      w_h2, b_h2, g_h2, bb_h2, \n",
    "                                      w_o, b_ho, g_ho, bb_ho, .0, .2)\n",
    "\n",
    "h, h2, py_x = model(X, w_h, b_h, g_h, bb_h, \n",
    "                    w_h2, b_h2, g_h2, bb_h2, \n",
    "                    w_o, b_ho, g_ho, bb_ho, .0, .0)\n",
    "\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "\n",
    "\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
    "params = [w_h, b_h, g_h, bb_h, w_h2, b_h2, g_h2, bb_h2, \n",
    "          w_o, b_ho, g_ho, bb_ho]\n",
    "updates = RMSprop(cost, params, lr=0.0001)\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "\n",
    "\n",
    "for i in range(51):\n",
    "\n",
    "    for start, end in zip(range(0, len(xTrain), batch_size), range(batch_size, len(xTrain), batch_size)):\n",
    "        cost = train(xTrain[start:end], yTrain[start:end])\n",
    "        \n",
    "    xTrain, yTrain = shuffle(xTrain, yTrain)\n",
    "    xTest, yTest   = shuffle(xTest, yTest)\n",
    "\n",
    "    trr, tr = [], []\n",
    "    for start, end in zip(range(0, len(xTrain), batch_size), range(batch_size, len(xTrain), batch_size)):        \n",
    "        trr += [np.argmax(yTrain[start:end], axis=1) == predict(xTrain[start:end])]\n",
    "\n",
    "    for start, end in zip(range(0, len(xTest), batch_size), range(batch_size, len(xTest), batch_size)):\n",
    "        tr += [np.argmax(yTest[start:end], axis=1) == predict(xTest[start:end])]\n",
    "\n",
    "    print \"Round: %-5s Test: %-14s Train: %-8s\" % (i, np.mean(tr), np.mean(trr))\n",
    "    \n",
    "print\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
